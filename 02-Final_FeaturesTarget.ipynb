{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pandas.io.json import json_normalize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(' ', 'r') as file:\n",
    "    data = json.load(file)\n",
    "df = pd.json_normalize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing missing values:\n",
    "Eliminate the row where is not revenue value for any year 2020, 2019, 2018, 2017, 2016. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminate the row where is not revenue value for any year 2020, 2019, 2018, 2017, 2016. \n",
    "# Later we return to discard the missing values in the REVENUE variable (target)\n",
    "df= df.dropna(subset=['revenue.2020','revenue.2019','revenue.2018','revenue.2017','revenue.2016',], how='all')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing extrem values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing extreme values 2020 \n",
    "# COVID extreme values:\n",
    "df = df[df.vat_number != 'BE0463648419']   #PFIZER INNOVATIVE SUPPLY POINT INTERNATIONAL = BE0463648419\n",
    "df = df[df.vat_number != 'BE0478242365']   #PFIZER SERVICE COMPANY = BE0478242365\n",
    "df = df[df.vat_number != 'BE0416375270']   #EXXONMOBIL PETROLEUM & CHEMICAL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing extreme values 2019\n",
    "df = df[df.vat_number != 'BE0822358674']     #GMED HEALTHCARE\n",
    "df = df[df.vat_number != 'BE0419457296']     #ONTEX\n",
    "df = df[df.vat_number != 'BE0473416418']     #TELENET\n",
    "df = df[df.vat_number != 'BE0405414072']     #UNILIN\n",
    "df = df[df.vat_number != 'BE0438282424']     #TECH DATA\n",
    "df = df[df.vat_number != 'BE0403196039']     #PHILIP MORRIS BENELUX\n",
    "df = df[df.vat_number != 'BE0403768933']     #ESTEE LAUDER\n",
    "df = df[df.vat_number != 'BE0888256714']     #ST. JUDE MEDICAL COORDINATION CENTER\n",
    "df = df[df.vat_number != 'BE0467071826']     #BLACK & DECKER LIMITED\n",
    "df = df[df.vat_number != 'BE0464298616']     #AVNET EUROPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for melteing the Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_revenue = pd.melt(df, id_vars=['nace_code','vat_number'], value_vars=['revenue.2020', 'revenue.2019','revenue.2018', 'revenue.2017', 'revenue.2016', 'revenue.2015'], var_name='year_revenue',value_name='revenue')\n",
    "df_revenue['id'] = df_revenue.nace_code.str.cat(df_revenue.vat_number)\n",
    "df_revenue['year']=df_revenue['year_revenue'].apply(lambda x: x[-4:])\n",
    "df_revenue['id'] = df_revenue.id.str.cat(df_revenue.year)\n",
    "df_revenue.drop(['nace_code','vat_number','year'], axis='columns', inplace=True)\n",
    "\n",
    "df_ebitda = pd.melt(df, id_vars=['company_name','nace_code','vat_number','creation_date','company_category', 'province'], value_vars=['ebitda.2020','ebitda.2019', 'ebitda.2018', 'ebitda.2017','ebitda.2016', 'ebitda.2015'], var_name='year_ebitda',value_name='ebitda')\n",
    "df_ebitda['id'] = df_ebitda.nace_code.str.cat(df_ebitda.vat_number)\n",
    "df_ebitda['year']=df_ebitda['year_ebitda'].apply(lambda x: x[-4:])\n",
    "df_ebitda['id'] = df_ebitda.id.str.cat(df_ebitda.year)\n",
    "\n",
    "df_assets = pd.melt(df, id_vars=['nace_code','vat_number'], value_vars=['total_assets.2020','total_assets.2019', 'total_assets.2018', 'total_assets.2017','total_assets.2016', 'total_assets.2015'], var_name='year_assets',value_name='total_assets')\n",
    "df_assets['id'] = df_assets.nace_code.str.cat(df_assets.vat_number)\n",
    "df_assets['year']=df_assets['year_assets'].apply(lambda x: x[-4:])\n",
    "df_assets['id'] = df_assets.id.str.cat(df_assets.year)\n",
    "df_assets.drop(['nace_code','vat_number','year'], axis='columns', inplace=True)\n",
    "\n",
    "df_staff_cost = pd.melt(df, id_vars=['nace_code','vat_number'], value_vars=['staff_costs.2020', 'staff_costs.2019', 'staff_costs.2018',\n",
    "       'staff_costs.2016', 'staff_costs.2017', 'staff_costs.2015'], var_name='year_staff_cost',value_name='staff_cost')\n",
    "df_staff_cost['id'] = df_staff_cost.nace_code.str.cat(df_staff_cost.vat_number)\n",
    "df_staff_cost['year']=df_staff_cost['year_staff_cost'].apply(lambda x: x[-4:])\n",
    "df_staff_cost['id'] = df_staff_cost.id.str.cat(df_staff_cost.year)\n",
    "df_staff_cost.drop(['nace_code','vat_number','year'], axis='columns', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.merge(pd.merge(df_ebitda,df_assets,on='id'), df_staff_cost, on='id')\n",
    "df_melt = pd.merge(df2, df_revenue, on='id')\n",
    "df_melt.drop(['year_ebitda','year_assets','year_staff_cost','year_revenue'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for coding 'company_category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_size(x):\n",
    "    '''\n",
    "    Function for coding the variable company_category\n",
    "    It is part of the features\n",
    "    '''\n",
    "    if x =='Small':\n",
    "        return 1\n",
    "    if x =='Medium sized':\n",
    "        return 2\n",
    "    if x =='Large':\n",
    "        return 3\n",
    "    if x =='Very large':\n",
    "        return 4\n",
    "\n",
    "df_melt['size_code'] = df_melt['company_category'].apply(code_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform string to date\n",
    "df_melt['DateFormat'] = pd.to_datetime(df_melt.creation_date, format=\"%Y/%m/%d\")\n",
    "#Extracting Year\n",
    "df_melt['creation_year'] = df_melt['DateFormat'].dt.year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking missing values\n",
    "df_melt.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop remainder missing values from the REVENUE variable (target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop remainder missing values from the REVENUE variable (target)\n",
    "df_melt= df_melt.dropna(subset=['revenue'], how='all')\n",
    "df_melt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can check that missing values from other variables decreased:\n",
    "df_melt.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the DataFrame Reference for filling the missing values\n",
    "\n",
    "#### DataFrame reference: Company size, province, the highest level of the Nace code and year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new nace code, only the highest level \n",
    "df_melt['highLevel_NaceCode']=df_melt['nace_code'].apply(lambda x: x[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping 'company_category','province','new_naceCode','year' by median \n",
    "grouped_median = df_melt.groupby(['company_category','province','highLevel_NaceCode','year']).agg({'ebitda': ['median']})\n",
    "grouped_median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling missing values base on its reference \n",
    "(company size, province, the highest level of the Nace code and year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling Nan values for every selected Feature (with missing values):\n",
    "\n",
    "#ebitda\n",
    "median_ebitda = df_melt.groupby(['company_category','province','highLevel_NaceCode','year'])['ebitda'].transform('median')\n",
    "df_melt.loc[df_melt['ebitda'].isnull(), 'ebitda'] = median_ebitda\n",
    "\n",
    "#total_assets\n",
    "median_totalAssets = df_melt.groupby(['company_category','province','highLevel_NaceCode','year'])['total_assets'].transform('median')\n",
    "df_melt.loc[df_melt['total_assets'].isnull(), 'total_assets'] = median_totalAssets\n",
    "\n",
    "#staff_cost\n",
    "median_staffCost = df_melt.groupby(['company_category','province','highLevel_NaceCode','year'])['staff_cost'].transform('median')\n",
    "df_melt.loc[df_melt['staff_cost'].isnull(), 'staff_cost'] = median_staffCost\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking remainder missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melt.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reducing the DataFrame reference one level for filling remainder missing values\n",
    "\n",
    "'Company size, province and the highest level of the Nace code'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for Ebitda, reducing the three (DataFrame reference) one level\n",
    "median_ebitda2 = df_melt.groupby(['company_category','province','highLevel_NaceCode'])['ebitda'].transform('median')\n",
    "df_melt.loc[df_melt['ebitda'].isnull(), 'ebitda'] = median_ebitda2\n",
    "\n",
    "#staff_cost, reducing the three (DataFrame reference) one level\n",
    "median_staff_Cost = df_melt.groupby(['company_category','province','highLevel_NaceCode'])['staff_cost'].transform('median')\n",
    "df_melt.loc[df_melt['staff_cost'].isnull(), 'staff_cost'] = median_staff_Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking, no missing values in the Ebitda variable:\n",
    "df_melt.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling the remainder missing values for staff_cost variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle the last missing values staff_cost, reducing the three (DataFrame reference) other level. \n",
    "# and instead median Input with the minimum value:\n",
    "median_staff_Cost = df_melt.groupby(['company_category','province'])['staff_cost'].transform('min')\n",
    "df_melt.loc[df_melt['staff_cost'].isnull(), 'staff_cost'] = median_staff_Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melt.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating variable Revenue + 1 year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue = df_melt.loc[:, ['nace_code','vat_number','year','revenue']]\n",
    "revenue.rename(columns={\"year\":\"year_ref\", \"revenue\":\"revenue_ref\"}, inplace = True)\n",
    "revenue['year_ref'] = revenue['year_ref'].astype(int)\n",
    "revenue['year_prev'] = revenue['year_ref'].apply(lambda x: x-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue['id'] = revenue.nace_code.str.cat(revenue.vat_number)\n",
    "revenue['year_prev'] = revenue['year_prev'].astype(str)\n",
    "revenue['id'] = revenue.id.str.cat(revenue.year_prev)\n",
    "revenue.drop(['nace_code','vat_number'], axis='columns', inplace=True)\n",
    "revenue = revenue[revenue.year_prev != '2014']\n",
    "revenue.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging the DataFrames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.merge(df_melt, revenue, on = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking consistency of the 'year' variable\n",
    "df_final['year'].equals(df_final['year_prev']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.rename(columns={\"revenue_ref\":\"revenue_target\", \"revenue\":\"revenue_feature\", \"size_code\":\"company_size\"}, inplace = True)\n",
    "df_final = df_final.loc[:,['vat_number','nace_code','highLevel_NaceCode','creation_year','year','province','company_size','total_assets', 'staff_cost', 'revenue_feature', 'revenue_target']]\n",
    "df_final.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check: the FEATURES doesn't have any missing values\n",
    "df_final.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers in the very large companies\n",
    "# Maintaining only company size: Small, Medium and Large\n",
    "df_final = df_final[df_final.company_size != 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#discarting companies created in 2019 (without financial history)\n",
    "df_final = df_final[df_final.creation_year != 2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the final file 'FinancialData.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the file 'FinancialData.csv'\n",
    "columns = ['vat_number', 'nace_code', 'highLevel_NaceCode', 'year', 'province',\n",
    "       'company_size', 'total_assets', 'staff_cost',\n",
    "       'revenue_feature', 'revenue_target']\n",
    "df_final = pd.DataFrame(data=df_final, columns=columns)\n",
    "df_final.to_csv(\"FinancialData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8d21f3b75a0e2120eb0e66e21d4adea905fc160c040159242535b1a26e9f956d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
